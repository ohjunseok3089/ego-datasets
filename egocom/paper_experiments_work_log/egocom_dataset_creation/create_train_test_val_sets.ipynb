{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is no need to run this file. It simply shows the procedure used to create the train, test, and val sets for documentation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video_info\n",
    "video_info = pd.read_csv(\"/datasets/cgn/EGOCOM/video_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, val, and test sets.\n",
    "video_info['gender'] = video_info['speaker_gender'] == 'male'\n",
    "video_info['cid'] = video_info['conversation_id'].apply(lambda x: x.split(\"__part\")[0])\n",
    "video_info['day'] = video_info['conversation_id'].apply(lambda x: int(x[4:5]))\n",
    "convs = video_info.groupby(['cid']).mean().drop(['video_id', 'video_speaker_id', 'speaker_is_host', 'word_count'], axis = 1)\n",
    "convs['duration_seconds'] = convs['duration_seconds'] > 500\n",
    "convs['native_speaker'] = convs['native_speaker'] < 1\n",
    "convs['gender'] = convs['gender'] < 1\n",
    "convs['day'] = convs['day'] > 2\n",
    "convs.drop([ 'background_music', 'gender', 'background_fan', 'duration_seconds'], axis = 1, inplace=True)\n",
    "strats = ['background_fan', 'background_music', 'native_speaker', 'speaker_gender', ]\n",
    "train_idx, test_idx = train_test_split(range(len(convs)), test_size = 0.2, stratify = convs, random_state = 0)\n",
    "val_idx = [test_idx[0], test_idx[-1]]\n",
    "test_idx = test_idx[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add information to video_info\n",
    "video_info = pd.read_csv(\"/datasets/cgn/EGOCOM/video_info.csv\")\n",
    "video_info['cid'] = video_info['conversation_id'].apply(lambda x: x.split(\"__part\")[0])\n",
    "train = pd.DataFrame([(z, i in train_idx) for i, z in enumerate(list(convs.index))], columns = ['cid', 'train'])\n",
    "val = pd.DataFrame([(z, i in val_idx) for i, z in enumerate(list(convs.index))], columns = ['cid', 'val'])\n",
    "test = pd.DataFrame([(z, i in test_idx) for i, z in enumerate(list(convs.index))], columns = ['cid', 'test'])\n",
    "video_info = pd.merge(video_info, train, on='cid')\n",
    "video_info = pd.merge(video_info, val, on='cid')\n",
    "video_info = pd.merge(video_info, test, on='cid')\n",
    "\n",
    "# Make sure all videos are accounted for\n",
    "assert(all(video_info[['train', 'val', 'test']].sum(axis = 1) == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store video_info\n",
    "video_info.to_csv(\"/datasets/cgn/EGOCOM/video_info.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
