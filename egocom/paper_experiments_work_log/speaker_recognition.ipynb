{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from egocom import audio\n",
    "from egocom.multi_array_alignment import gaussian_kernel\n",
    "from egocom.transcription import async_srt_format_timestamp\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from egocom.transcription import write_subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_smoothing(arr, samplerate = 44100, window_size = 0.1):\n",
    "    '''Returns a locally-normalized array by dividing each point by a the \n",
    "    sum of the points around it, with greater emphasis on the points \n",
    "    nearest (using a Guassian convolution)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.array\n",
    "    samplerate : int\n",
    "    window_size : float (in seconds)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A Guassian smoothing of the input arr'''\n",
    "    \n",
    "    kern = gaussian_kernel(kernel_length=int(samplerate * window_size), nsigma=3)\n",
    "    return np.convolve(arr, kern, 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests for audio.avg_pool_1d\n",
    "\n",
    "def test_exact_recoverability(\n",
    "    arr = range(10),\n",
    "    pool_size = 4,\n",
    "    weights = [0.2,0.3,0.3,0.2],\n",
    "): \n",
    "    '''Verify that downsampled signal can be fully recovered exactly.'''\n",
    "    complete_result = audio.avg_pool_1d(range(10), pool_size, filler = True, weights = weights)\n",
    "    downsampled_result = audio.avg_pool_1d(range(10), pool_size, filler = False, weights = weights)\n",
    "    # Try to recover filled_pooled_mags using the downsampled pooled_mags\n",
    "    upsampled_result = audio.upsample_1d(downsampled_result, len(arr), pool_size)\n",
    "    assert(np.all(upsampled_result == complete_result))\n",
    "    \n",
    "    \n",
    "def test_example(\n",
    "    arr = range(10),\n",
    "    pool_size = 4,\n",
    "    weights = [0.2,0.3,0.3,0.2],\n",
    "):\n",
    "    '''Verify that avg_pool_1d produces the result we expect.'''\n",
    "    result = audio.avg_pool_1d(range(10), pool_size, weights = weights)\n",
    "    expected = np.array([1.5, 1.5, 1.5, 1.5, 5.5, 5.5, 5.5, 5.5, 8.5, 8.5])\n",
    "    assert(np.all(result - expected < 1e-6))\n",
    "    \n",
    "test_exact_recoverability()\n",
    "test_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate speaker labels from max raw audio magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/cgn/Dropbox (Facebook)/EGOCOM/raw_audio/wav/'\n",
    "\n",
    "fn_dict = {}\n",
    "for fn in sorted(os.listdir(data_dir)):\n",
    "    key = fn[9:23] + fn[32:37] if 'part' in fn else fn[9:21]\n",
    "    fn_dict[key] = fn_dict[key] + [fn] if key in fn_dict else [fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_1__con_1__part1 | day_1__con_1__part2 | day_1__con_1__part3 | day_1__con_1__part4 | day_1__con_1__part5 | day_1__con_2__part1 | day_1__con_2__part2 | day_1__con_2__part3 | day_1__con_2__part4 | day_1__con_2__part5 | day_1__con_3__part1 | day_1__con_3__part2 | day_1__con_3__part3 | day_1__con_3__part4 | day_1__con_4__part1 | day_1__con_4__part2 | day_1__con_4__part3 | day_1__con_4__part4 | day_1__con_5__part1 | day_1__con_5__part2 | day_1__con_5__part3 | day_1__con_5__part4 | day_1__con_5__part5 | day_2__con_1__part1 | day_2__con_1__part2 | day_2__con_1__part3 | day_2__con_1__part4 | day_2__con_1__part5 | day_2__con_2__part1 | day_2__con_2__part2 | day_2__con_2__part3 | day_2__con_2__part4 | day_2__con_3 | day_2__con_4 | day_2__con_5 | day_2__con_6 | day_2__con_7 | day_3__con_1 | day_3__con_2 | day_3__con_3 | day_3__con_4 | day_3__con_5 | day_3__con_6 | day_4__con_1 | day_4__con_2 | day_4__con_3 | day_4__con_4 | day_4__con_5 | day_4__con_6 | day_5__con_1 | day_5__con_2 | day_5__con_3 | day_5__con_4 | day_5__con_5 | day_5__con_6 | day_5__con_7 | day_5__con_8 | day_6__con_1 | day_6__con_2 | day_6__con_3 | day_6__con_4 | day_6__con_5 | day_6__con_6 | "
     ]
    }
   ],
   "source": [
    "samplerate = 44100\n",
    "window = 1 # Averages signals with windows of N seconds.\n",
    "window_length = int(samplerate * window)\n",
    "\n",
    "labels = {}\n",
    "for key in list(fn_dict.keys()):\n",
    "    print(key, end = \" | \")\n",
    "    fns = fn_dict[key]\n",
    "    wavs = [wavfile.read(data_dir + fn)[1] for fn in fns]\n",
    "    duration = min(len(w) for w in wavs)\n",
    "    wavs = np.stack([w[:duration] for w in wavs])\n",
    "    \n",
    "    # Only use the magnitudes of both left and right for each audio wav.\n",
    "    mags = abs(wavs).sum(axis = 2) \n",
    "\n",
    "    # DOWNSAMPLED (POOLED) Discretized/Fast (no overlap) gaussian smoothing with one-second time window.\n",
    "    kwargs = {\n",
    "        'pool_size': window_length, \n",
    "        'weights': gaussian_kernel(kernel_length=window_length),\n",
    "        'filler': False,\n",
    "    }\n",
    "    pooled_mags = np.apply_along_axis(audio.avg_pool_1d, 1, mags, **kwargs) \n",
    "\n",
    "    # Create noisy speaker labels\n",
    "    threshold = np.percentile(pooled_mags, 10, axis = 1)\n",
    "    no_one_speaking = (pooled_mags > np.expand_dims(threshold, axis = 1)).sum(axis = 0) == 0\n",
    "    speaker_labels = np.argmax(pooled_mags, axis = 0)\n",
    "    speaker_labels[no_one_speaking] = -1\n",
    "    \n",
    "    # User 1-based indexing for speaker labels (ie increase by 1)\n",
    "    speaker_labels = [z if z < 0 else z + 1 for z in speaker_labels]\n",
    "    \n",
    "    # Store results\n",
    "    labels[key] = speaker_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write result to file\n",
    "loc = '/Users/cgn/Dropbox (Facebook)/EGOCOM/raw_audio_speaker_labels_{}.json'.format(str(window))\n",
    "def default(o):\n",
    "    if isinstance(o, np.int64): return int(o)  \n",
    "    raise TypeError\n",
    "    \n",
    "import json\n",
    "with open(loc, 'w') as fp:\n",
    "    json.dump(labels, fp, default = default)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read result into a dict\n",
    "import json\n",
    "with open(loc, 'r') as fp:\n",
    "    labels = json.load(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ground truth speaker labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt_speaker_labels(\n",
    "    df_times_speaker,\n",
    "    duration_in_seconds,\n",
    "    time_window_seconds = 0.5,\n",
    "):\n",
    "    stack = rev_times[::-1]\n",
    "    stack_time = stack.pop()\n",
    "    label_times = np.arange(0, duration_in_seconds, time_window_seconds)\n",
    "    result = [-1] * len(label_times)\n",
    "\n",
    "    for i, t in enumerate(label_times):\n",
    "        while stack_time['endTime'] > t and stack_time['endTime'] <= t + time_window_seconds:\n",
    "            result[i] = stack_time['speaker']\n",
    "            if len(stack) == 0:\n",
    "                break\n",
    "            stack_time = stack.pop()\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/cgn/Dropbox (Facebook)/EGOCOM/ground_truth_transcriptions.csv\")[\n",
    "    [\"key\", \"endTime\", \"speaker\", ]\n",
    "].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_1__con_1__part1 | day_1__con_1__part2 | day_1__con_1__part3 | day_1__con_1__part4 | day_1__con_1__part5 | day_1__con_2__part1 | day_1__con_2__part2 | day_1__con_2__part3 | day_1__con_2__part4 | day_1__con_2__part5 | day_1__con_3__part1 | day_1__con_3__part2 | day_1__con_3__part3 | day_1__con_3__part4 | day_1__con_4__part1 | day_1__con_4__part2 | day_1__con_4__part3 | day_1__con_4__part4 | day_1__con_5__part1 | day_1__con_5__part2 | day_1__con_5__part3 | day_1__con_5__part4 | day_1__con_5__part5 | day_2__con_1__part1 | day_2__con_1__part2 | day_2__con_1__part3 | day_2__con_1__part4 | day_2__con_1__part5 | day_2__con_2__part1 | day_2__con_2__part2 | day_2__con_2__part3 | day_2__con_2__part4 | day_2__con_3 | day_2__con_4 | day_2__con_5 | day_2__con_6 | day_2__con_7 | day_3__con_1 | day_3__con_2 | day_3__con_3 | day_3__con_4 | day_3__con_5 | day_3__con_6 | day_4__con_1 | day_4__con_2 | day_4__con_3 | day_4__con_4 | day_4__con_5 | day_4__con_6 | day_5__con_1 | day_5__con_2 | day_5__con_3 | day_5__con_4 | day_5__con_5 | day_5__con_6 | day_5__con_7 | day_5__con_8 | day_6__con_1 | day_6__con_2 | day_6__con_3 | day_6__con_4 | day_6__con_5 | day_6__con_6 | "
     ]
    }
   ],
   "source": [
    "gt_speaker_labels = {}\n",
    "for key, sdf in df.groupby('key'):\n",
    "    print(key, end = \" | \")\n",
    "    wavs = [wavfile.read(data_dir + fn)[1] for fn in fn_dict[key]]\n",
    "    duration = min(len(w) for w in wavs)\n",
    "    DL = sdf[[\"endTime\", \"speaker\"]].to_dict('list')\n",
    "    rev_times = [dict(zip(DL,t)) for t in zip(*DL.values())]\n",
    "    duration_in_seconds = np.ceil(duration / float(samplerate))\n",
    "    gt_speaker_labels[key] = create_gt_speaker_labels(rev_times, duration_in_seconds, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write result to file\n",
    "loc = '/Users/cgn/Dropbox (Facebook)/EGOCOM/rev_ground_truth_speaker_labels_{}.json'.format(str(window))\n",
    "with open(loc, 'w') as fp:\n",
    "    json.dump(gt_speaker_labels, fp, default = default)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read result into a dict\n",
    "with open(loc, 'r') as fp:\n",
    "    gt_speaker_labels = json.load(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_1__con_1__part1 0.724\n",
      "day_1__con_1__part2 0.763\n",
      "day_1__con_1__part3 0.702\n",
      "day_1__con_1__part4 0.773\n",
      "day_1__con_1__part5 0.867\n",
      "day_1__con_2__part1 0.68\n",
      "day_1__con_2__part2 0.742\n",
      "day_1__con_2__part3 0.792\n",
      "day_1__con_2__part4 0.869\n",
      "day_1__con_2__part5 0.85\n",
      "day_1__con_3__part1 0.822\n",
      "day_1__con_3__part2 0.735\n",
      "day_1__con_3__part3 0.758\n",
      "day_1__con_3__part4 0.867\n",
      "day_1__con_4__part1 0.859\n",
      "day_1__con_4__part2 0.833\n",
      "day_1__con_4__part3 0.77\n",
      "day_1__con_4__part4 0.72\n",
      "day_1__con_5__part1 0.666\n",
      "day_1__con_5__part2 0.607\n",
      "day_1__con_5__part3 0.637\n",
      "day_1__con_5__part4 0.67\n",
      "day_1__con_5__part5 0.6\n",
      "day_2__con_1__part1 0.699\n",
      "day_2__con_1__part2 0.743\n",
      "day_2__con_1__part3 0.723\n",
      "day_2__con_1__part4 0.68\n",
      "day_2__con_1__part5 0.714\n",
      "day_2__con_2__part1 0.715\n",
      "day_2__con_2__part2 0.68\n",
      "day_2__con_2__part3 0.677\n",
      "day_2__con_2__part4 0.633\n",
      "day_2__con_3 0.623\n",
      "day_2__con_4 0.754\n",
      "day_2__con_5 0.842\n",
      "day_2__con_6 0.728\n",
      "day_2__con_7 0.663\n",
      "day_3__con_1 0.868\n",
      "day_3__con_2 0.787\n",
      "day_3__con_3 0.769\n",
      "day_3__con_4 0.793\n",
      "day_3__con_5 0.685\n",
      "day_3__con_6 0.741\n",
      "day_4__con_1 0.784\n",
      "day_4__con_2 0.669\n",
      "day_4__con_3 0.736\n",
      "day_4__con_4 0.777\n",
      "day_4__con_5 0.423\n",
      "day_4__con_6 0.708\n",
      "day_5__con_1 0.731\n",
      "day_5__con_2 0.693\n",
      "day_5__con_3 0.731\n",
      "day_5__con_4 0.723\n",
      "day_5__con_5 0.727\n",
      "day_5__con_6 0.783\n",
      "day_5__con_7 0.682\n",
      "day_5__con_8 0.612\n",
      "day_6__con_1 0.78\n",
      "day_6__con_2 0.686\n",
      "day_6__con_3 0.678\n",
      "day_6__con_4 0.558\n",
      "day_6__con_5 0.636\n",
      "day_6__con_6 0.598\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for key in labels.keys():\n",
    "    true = gt_speaker_labels[key]\n",
    "    pred = labels[key]\n",
    "    if len(true) > len(pred):\n",
    "        true = true[:-1]\n",
    "#         diff = round(accuracy_score(true[:-1], pred) - accuracy_score(true[1:], pred), 3)\n",
    "#         scores.append(diff)\n",
    "#         print(key, accuracy_score(true[1:], pred), accuracy_score(true[:-1], pred), diff)\n",
    "    score = accuracy_score(true, pred)\n",
    "    scores.append(score)\n",
    "    print(key, np.round(score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 72.3%\n"
     ]
    }
   ],
   "source": [
    "print('Average accuracy:', str(np.round(np.mean(scores), 3)* 100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day_1__con_1__part1 | day_1__con_1__part2 | day_1__con_1__part3 | day_1__con_1__part4 | day_1__con_1__part5 | day_1__con_2__part1 | day_1__con_2__part2 | day_1__con_2__part3 | day_1__con_2__part4 | day_1__con_2__part5 | day_1__con_3__part1 | day_1__con_3__part2 | day_1__con_3__part3 | day_1__con_3__part4 | day_1__con_4__part1 | day_1__con_4__part2 | day_1__con_4__part3 | day_1__con_4__part4 | day_1__con_5__part1 | day_1__con_5__part2 | day_1__con_5__part3 | day_1__con_5__part4 | day_1__con_5__part5 | day_2__con_1__part1 | day_2__con_1__part2 | day_2__con_1__part3 | day_2__con_1__part4 | day_2__con_1__part5 | day_2__con_2__part1 | day_2__con_2__part2 | day_2__con_2__part3 | day_2__con_2__part4 | day_2__con_3 | day_2__con_4 | day_2__con_5 | day_2__con_6 | day_2__con_7 | day_3__con_1 | day_3__con_2 | day_3__con_3 | day_3__con_4 | day_3__con_5 | day_3__con_6 | day_4__con_1 | day_4__con_2 | day_4__con_3 | day_4__con_4 | day_4__con_5 | day_4__con_6 | day_5__con_1 | day_5__con_2 | day_5__con_3 | day_5__con_4 | day_5__con_5 | day_5__con_6 | day_5__con_7 | day_5__con_8 | day_6__con_1 | day_6__con_2 | day_6__con_3 | day_6__con_4 | day_6__con_5 | day_6__con_6 | "
     ]
    }
   ],
   "source": [
    "loc = '/Users/cgn/Dropbox (Facebook)/EGOCOM/subtitles/'\n",
    "for key in labels.keys():\n",
    "    gt = gt_speaker_labels[key]\n",
    "    est = labels[key]\n",
    "    with open(loc + \"speaker_\" + key + '.srt', 'w') as f:\n",
    "        print(key, end = \" | \")\n",
    "        for t, s_est in enumerate(est):\n",
    "            s_gt = gt[t]\n",
    "            print(t + 1, file = f)\n",
    "            print(async_srt_format_timestamp(t*window), end = \"\", file = f)\n",
    "            print(' --> ', end = '', file = f)\n",
    "            print(async_srt_format_timestamp(t*window+window), file = f)\n",
    "            print('Rev.com Speaker:', end = \" \", file = f)\n",
    "            if s_gt == -1:\n",
    "                print('No one is speaking', file = f)\n",
    "            elif s_gt == 1:\n",
    "                print('Curtis', file = f)\n",
    "            else:\n",
    "                print('Speaker ' + str(s_gt), file = f)\n",
    "            print('MaxMag Speaker:', end = \" \", file = f)\n",
    "            if s_est == -1:\n",
    "                print('No one is speaking', file = f)\n",
    "            elif s_est == 1:\n",
    "                print('Curtis', file = f)\n",
    "            else:\n",
    "                print('Speaker ' + str(s_est), file = f)\n",
    "            print(file = f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate subtitles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in labels.keys():\n",
    "    gt = labels[key]\n",
    "    with open(\"subtitles/est_\" + key + '.srt', 'w') as f:\n",
    "        for t, s in enumerate(gt):\n",
    "            print(t + 1, file = f)\n",
    "            print(async_srt_format_timestamp(t*window), end = \"\", file = f)\n",
    "            print(' --> ', end = '', file = f)\n",
    "            print(async_srt_format_timestamp(t*window+window), file = f)\n",
    "            print('Max mag of wavs speaker id', file = f)\n",
    "            if s == -1:\n",
    "                print('No one is speaking', file = f)\n",
    "            elif s == 1:\n",
    "                print('Curtis', file = f)\n",
    "            else:\n",
    "                print('Speaker ' + str(s), file = f)\n",
    "            print(file = f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
